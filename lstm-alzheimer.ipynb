{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install keras\n",
    "%pip install pandas\n",
    "%pip install -U scikit-learn\n",
    "%pip install torch\n",
    "%pip install einops\n",
    "%pip install torchvision\n",
    "%pip install torch\n",
    "%pip install icecream\n",
    "%pip install tqdm\n",
    "%pip install nibabel\n",
    "%pip install numpy\n",
    "%pip install NiLearn\n",
    "%pip install matplotlib\n",
    "%pip install scikit-image\n",
    "%pip install jupyter_capture_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, LeakyReLU, Dense, Flatten, Reshape, UpSampling2D,BatchNormalization, Dropout, Conv3D, Conv3DTranspose, Conv2D, Conv2DTranspose, ConvLSTM2D\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import Sequential, callbacks\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import icecream as ic\n",
    "import tqdm\n",
    "import nibabel as nib\n",
    "from nibabel import processing\n",
    "from nilearn import plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.transform as skTrans\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the model definitions\n",
    "\n",
    "training_output = open(\"training_output.txt\", \"a\")\n",
    "\n",
    "step_size = 3\n",
    "batch_size=1\n",
    "dim_size = 128\n",
    "d_losses=[]\n",
    "g_losses=[]\n",
    "d_accuracies=[]\n",
    "g_accuracies=[]\n",
    "iteration_checkpoints=[]\n",
    "\n",
    "# Fake Image Label: All 1\n",
    "fake = np.ones((batch_size, 1))\n",
    "\n",
    "# Real Image Labels: All 0\n",
    "real = np.zeros((batch_size, 1))\n",
    "\n",
    "# 2D slices from 3D image\n",
    "slices = [96,128]\n",
    "\n",
    "def get_slice(image, slice_index):\n",
    "\tindex = int((image.shape[0]/256) * slices[slice_index])\n",
    "\treturn image[index]\n",
    "\n",
    "def get_slice_list(imagelist, slice_index):\n",
    "\tlist = []\n",
    "\tfor image in imagelist:\n",
    "\t\tindex = int((image.shape[0]/256) * slices[slice_index])\n",
    "\t\tlist.append(image[index])\n",
    "\treturn np.array(list)\n",
    "\n",
    "def create_generator():\n",
    "\t# 2D LSTM\n",
    "\tgenerator = Sequential(name='generator')\n",
    "\tgenerator.add(Input(shape=(step_size, dim_size, dim_size)))\n",
    "\tgenerator.add(Reshape((step_size, dim_size, dim_size, 1)))\n",
    "\tgenerator.add(ConvLSTM2D(dim_size, (7, 7), strides=(1, 1), padding='same', return_sequences=True, activation='relu'))\n",
    "\tgenerator.add(BatchNormalization())\n",
    "\tgenerator.add(ConvLSTM2D(dim_size, (5, 5), strides=(1, 1), padding='same', return_sequences=True, activation='relu'))\n",
    "\tgenerator.add(BatchNormalization())\n",
    "\tgenerator.add(ConvLSTM2D(dim_size, (3, 3), strides=(1, 1), padding='same', return_sequences=True, activation='relu'))\n",
    "\tgenerator.add(BatchNormalization())\n",
    "\tgenerator.add(ConvLSTM2D(dim_size, (1, 1), strides=(1, 1), padding='same', return_sequences=True, activation='relu'))\n",
    "\tgenerator.add(BatchNormalization())\n",
    "\tgenerator.add(ConvLSTM2D(1, (1, 1), strides=(1, 1), padding='same', activation='sigmoid'))\n",
    "\n",
    "\tgenerator.add(Reshape((dim_size, dim_size)))\n",
    "\n",
    "\tgenerator_optimizer = tf.optimizers.Adam(1e-4)\n",
    "\tgenerator.compile(optimizer=generator_optimizer, loss='mse', metrics=['accuracy'])\n",
    "\tgenerator.summary()\n",
    "\treturn generator\n",
    "\n",
    "def create_discriminator():\n",
    "\tdiscriminator_input = Input(shape=(dim_size, dim_size))\n",
    "\ty = Dense(dim_size)(discriminator_input)\n",
    "\ty = LeakyReLU(alpha=0.05)(y)\n",
    "\ty = Dense(64)(y)\n",
    "\ty = LeakyReLU(alpha=0.05)(y)\n",
    "\ty = Flatten()(y)\n",
    "\ty = Dense(32)(y)\n",
    "\ty = LeakyReLU(alpha=0.05)(y)\n",
    "\ty = Dense(1, activation='sigmoid')(y)\n",
    "\tdiscriminator = Model(discriminator_input, y)\n",
    "\t#discriminator_optimizer = RMSprop(learning_rate=8e-4, clipvalue=1.0, decay=1e-8)\n",
    "\tdiscriminator_optimizer = tf.optimizers.Adam(1e-4)\n",
    "\tdiscriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\tdiscriminator.trainable = False\n",
    "\tdiscriminator.summary()\n",
    "\treturn discriminator\n",
    "\n",
    "def create_gan(generator, discriminator):\n",
    "\tgan_input = Input(shape=(step_size, dim_size, dim_size))\n",
    "\tgan_output = discriminator(generator(gan_input))\n",
    "\tgan = Model(gan_input, gan_output)\n",
    "\t#gan_optimizer = RMSprop(learning_rate=4e-4, clipvalue=1.0, decay=1e-8)\n",
    "\tgan_optimizer = tf.optimizers.Adam(1e-4)\n",
    "\tgan.compile(optimizer=gan_optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\tgan.summary()\n",
    "\treturn gan\n",
    "\n",
    "def train_lstm(generator, iteration, X, Y, index, filename):\n",
    "\ttemp_X = get_slice_list(copy.deepcopy(X), index).reshape(batch_size, step_size, dim_size, dim_size)\n",
    "\ttemp_Y = get_slice(copy.deepcopy(Y), index).reshape(batch_size, dim_size, dim_size)\n",
    "\n",
    "\tfor i in range(1):\n",
    "\t\tg_loss, g_accuracy = generator.train_on_batch(temp_X, temp_Y)\n",
    "\n",
    "    # Save loss and accuracy to plot graphs after training\n",
    "\tg_losses.append(g_loss)\n",
    "\tg_accuracies.append(100.0 * g_accuracy)\n",
    "\titeration_checkpoints.append(iteration)\n",
    "\n",
    "\tif iteration % 20 == 0:\n",
    "\t\tplot_image(generator.predict(temp_X)[0], filename)\n",
    "\t\ttraining_output.write(\"Epoch: %d [Generator loss: %f, accuracy: %.2f%%]\\n\" % (iteration, g_loss, 100 * g_accuracy))\n",
    "\t\ttraining_output.flush()\n",
    "\n",
    "\n",
    "def train_gan(generator, discriminator, gan, iteration, X, Y, index, filename):\n",
    "\n",
    "\ttemp_X = get_slice_list(copy.deepcopy(X), index).reshape(batch_size, step_size, dim_size, dim_size)\n",
    "\ttemp_Y = get_slice(copy.deepcopy(Y), index).reshape(batch_size, dim_size, dim_size)\n",
    "\n",
    "\tfor i in range(10000):\n",
    "\t\tg_loss, g_accuracy = generator.train_on_batch(temp_X, temp_Y)\n",
    "\t\tif i % 10 == 0:\n",
    "\t\t\tplot_image(generator.predict(temp_X)[0], filename)\n",
    "\t\t\ttraining_output.write(\"Epoch: %d [Generator loss: %f, accuracy: %.2f%%]\\n\" % (iteration, g_loss, 100 * g_accuracy))\n",
    "\t\t\ttraining_output.flush()\n",
    "\n",
    "\tpredictions = generator.predict(temp_X)\n",
    "\n",
    "\tfor i in range(10):\n",
    "\t\td_loss, d_accuracy = discriminator.train_on_batch(np.concatenate([predictions, temp_Y], 0), np.concatenate([fake, real], 0))\n",
    "\n",
    "\tfor i in range(10):\n",
    "\t\tgan_loss, gan_accuracy = gan.train_on_batch(temp_X, real)\n",
    "\n",
    "    # Save loss and accuracy to plot graphs after training\n",
    "\td_losses.append(d_loss)\n",
    "\tg_losses.append(g_loss)\n",
    "\td_accuracies.append(100.0 * d_accuracy)\n",
    "\tg_accuracies.append(100.0 * g_accuracy)\n",
    "\n",
    "\titeration_checkpoints.append(iteration)\n",
    "\n",
    "\tplt.imshow(generator.predict(temp_X)[0], cmap='bone')\n",
    "\tplt.axis('off')\n",
    "\tplt.show()\n",
    "\tplt.savefig(filename)\n",
    "\n",
    "\ttraining_output.write(\"Epoch: %d [Disciminator loss: %f, accuracy: %.2f%%], [Generator loss: %f, accuracy: %.2f%%] [Gan loss: %f, accuracy: %.2f%%]\\n\" % (iteration, d_loss, 100.0 * d_accuracy, g_loss, 100 * g_accuracy,  gan_loss, 100 * gan_accuracy))\n",
    "\ttraining_output.flush()\n",
    "\n",
    "def plot_learning_process(label, values, filename):\n",
    "    plt.figure(figsize=(24, 10))\n",
    "    plt.title('Visualization of the learning process', fontsize=16)\n",
    "    plt.plot(np.arange(1, len(values) + 1), values)\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel(label, fontsize=16)\n",
    "    plt.xticks(fontsize=16)\n",
    "    plt.yticks(fontsize=16)\n",
    "    plt.xlim(1, len(values))\n",
    "    plt.grid()\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "def plot_image(image, filename):\n",
    "\n",
    "\tf, axs = plt.subplots()\n",
    "\tf.set_figheight(2.15)\n",
    "\tf.set_figwidth(2.15)\n",
    "\n",
    "\t#Plot original images\n",
    "\tplt.imshow(image, cmap='bone')\n",
    "\tplt.axis('off')\n",
    "\tplt.savefig(filename)\n",
    "\tplt.show()\n",
    "\n",
    "def plot_images(image1, image2, image3, image4, index, filename):\n",
    "\n",
    "\tf, axs = plt.subplots(1, 4)\n",
    "\n",
    "\t#Plot original images\n",
    "\taxs[0].imshow(get_slice(image1, index), cmap='bone')\n",
    "\taxs[1].imshow(get_slice(image2, index), cmap='bone')\n",
    "\taxs[2].imshow(get_slice(image3, index), cmap='bone')\n",
    "\taxs[3].imshow(get_slice(image4, index), cmap='bone')\n",
    "\n",
    "\taxs[0].axis('off')\n",
    "\taxs[1].axis('off')\n",
    "\taxs[2].axis('off')\n",
    "\taxs[3].axis('off')\n",
    "\n",
    "\tf.set_figheight(2.5)\n",
    "\tf.set_figwidth(10)\n",
    "\n",
    "\tplt.savefig(filename)\n",
    "\tplt.show()\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "\twith open(filename, 'rb') as inp:\n",
    "\t\tobj = pickle.load(inp)\n",
    "\treturn obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all the images from AD directory and training the AD model\n",
    "\n",
    "data_dir = './dataset'\n",
    "ad_generator_checkpoint = './checkpoints/ad_generator_checkpoint.weights.h5'\n",
    "ad_generator_checkpoint_backup = './checkpoints/ad_generator_checkpoint_%d.weights.h5'\n",
    "state_checkpoint = './checkpoints/state_checkpoint'\n",
    "cell_output_dir = './cell_output'\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "\n",
    "AD_generator = create_generator()\n",
    "AD_discriminator = create_discriminator()\n",
    "AD_gan = create_gan(AD_generator, AD_discriminator)\n",
    "AD_image_count = 0\n",
    "loop_index = 0\n",
    "\n",
    "# Reload the model and intermediate state if checkpoint files exist\n",
    "# This is done to recover the progress from process crashes\n",
    "if os.path.exists(ad_generator_checkpoint):\n",
    "    AD_generator.load_weights(ad_generator_checkpoint)\n",
    "\n",
    "if os.path.exists(state_checkpoint):\n",
    "    objs = load_object(state_checkpoint)\n",
    "    g_losses = objs[0]\n",
    "    g_accuracies = objs[1]\n",
    "    iteration_checkpoints = objs[2]\n",
    "    AD_image_count = objs[3]\n",
    "    loop_index = objs[4]\n",
    "\n",
    "while loop_index < 2000:\n",
    "    loop_index = loop_index + 1\n",
    "    for stage_dir in os.scandir(train_dir):\n",
    "        if not stage_dir.is_dir():\n",
    "            continue\n",
    "        for patient_dir in os.scandir(stage_dir.path):\n",
    "            if not patient_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            date_dirs = []\n",
    "            for scantype in os.listdir(patient_dir.path):\n",
    "                scantype_dir = patient_dir.path + \"/\" + scantype\n",
    "                if not (os.path.isdir(scantype_dir)):\n",
    "                    continue\n",
    "                date_dirs += os.listdir(scantype_dir)\n",
    "\n",
    "            date_dirs.sort()\n",
    "\n",
    "            #find all nii_files in sorted order by date\n",
    "            nii_files = []\n",
    "            for date in date_dirs:\n",
    "                for scantype_dir in os.listdir(patient_dir.path):\n",
    "                    date_dir = os.path.join(patient_dir.path, scantype_dir, date)\n",
    "                    nii_file = glob.glob(os.path.join(date_dir, '**', '*.nii'))\n",
    "                    if nii_file:\n",
    "                        nii_files.append(nii_file[0])\n",
    "                        continue\n",
    "\n",
    "            if len(nii_files) != 4:\n",
    "                print (\"nii file missing! patient: \" + patient_dir.path)\n",
    "                continue\n",
    "\n",
    "            nii_imglist = []\n",
    "            resized_imglist = []\n",
    "            normalized_resized_imglist = []\n",
    "\n",
    "            #load the image data\n",
    "            for i in range(len(nii_files)):\n",
    "                nii_img = nib.load(nii_files[i]).get_fdata()\n",
    "                if (nii_img.shape[0] != 256):\n",
    "                    print (\"skipping the image\")\n",
    "                    break\n",
    "\n",
    "                resized_img = skTrans.resize(nii_img, (dim_size,dim_size,dim_size), order=1, preserve_range=True)\n",
    "                normalized_resized_img = MinMaxScaler().fit_transform(np.reshape(resized_img, (-1,1))).reshape(dim_size,dim_size,dim_size)\n",
    "\n",
    "                nii_imglist.append(nii_img)\n",
    "                resized_imglist.append(resized_img)\n",
    "                normalized_resized_imglist.append(normalized_resized_img)\n",
    "\n",
    "\n",
    "            if len(normalized_resized_imglist) != 4:\n",
    "                continue\n",
    "\n",
    "            if(\"/CN/\" in nii_files[0]):\n",
    "                #CNfirst_transition.append(nii_files_tuple)\n",
    "                print (\"CN file loaded\")\n",
    "            elif(\"/MCI/\" in nii_files[0]):\n",
    "                #MCIfirst_transition.append(nii_files_tuple)\n",
    "                print (\"MCI file loaded\")\n",
    "            elif(\"/AD/\" in nii_files[0]):\n",
    "\n",
    "                if AD_image_count % 20 == 0:\n",
    "                    # Plotting the original sequence of images\n",
    "                    filename=cell_output_dir + \"/image_squence_\" + str(loop_index) + \"_\" + str(AD_image_count) + \".png\"\n",
    "                    plot_images(normalized_resized_imglist[:3][0], normalized_resized_imglist[:3][1], normalized_resized_imglist[:3][2], normalized_resized_imglist[3:][0], 0, filename)\n",
    "\n",
    "                # Training the model\n",
    "                filename=cell_output_dir + \"/predicted_image_\" + str(loop_index) + \"_\" + str(AD_image_count) + \".png\"\n",
    "                train_lstm(AD_generator, AD_image_count, normalized_resized_imglist[:3], normalized_resized_imglist[3:][0], 0, filename)\n",
    "\n",
    "                AD_image_count += 1\n",
    "\n",
    "                #train_gan(AD_generator, AD_discriminator, AD_gan, AD_image_count, normalized_resized_imglist[:3], normalized_resized_imglist[3:][0], slice_index, filename)\n",
    "\n",
    "    # Saving the state\n",
    "    AD_generator.save_weights(ad_generator_checkpoint_backup % loop_index)\n",
    "    AD_generator.save_weights(ad_generator_checkpoint)\n",
    "    save_object([g_losses, g_accuracies, iteration_checkpoints, AD_image_count, loop_index], state_checkpoint)\n",
    "\n",
    "#plot_learning_process(\"Discriminator Loss\", d_losses, cell_output_dir + \"/plot_learning_process_discriminator_loss.png\")\n",
    "#plot_learning_process(\"Discriminator Accuracy\", d_accuracies, cell_output_dir + \"/plot_learning_process_discriminator_accuracy.png\")\n",
    "#plot_learning_process(\"Gan Loss\", g_losses, cell_output_dir + \"/plot_learning_process_gan_loss.png\")\n",
    "#plot_learning_process(\"Gan Accuracy\", g_accuracies, cell_output_dir + \"/plot_learning_process_gan_accuracy.png\")\n",
    "plot_learning_process(\"Generator Loss\", g_losses, cell_output_dir + \"/plot_learning_process_generator_loss.png\")\n",
    "plot_learning_process(\"Generator Accuracy\", g_accuracies, cell_output_dir + \"/plot_learning_process_generator_accuracy.png\")\n",
    "print(\"Total number of image sequences processed: %d\" % AD_image_count)\n",
    "print(\"done processing train scans\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
